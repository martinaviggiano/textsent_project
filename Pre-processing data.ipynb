{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA IMPORT\n",
    "Hate speech dataset from a white supremacist forum:  https://github.com/Vicomtech/hate-speech-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import ntpath\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import nltk.sentiment.vader as vd\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import download\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    plot_confusion_matrix,\n",
    "    plot_precision_recall_curve,\n",
    "    plot_roc_curve,\n",
    ")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import sklearn as sk\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as VS\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "import preprocessor as pproc\n",
    "from cleantext import clean\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\tqdm\\std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\marti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_paths = glob.glob(\"hate-speech-dataset/all_files/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_paths = [f for f in all_files_paths if os.path.isfile(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_names = [str(ntpath.basename(f)).replace(\".txt\", \"\") for f in all_files_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Error removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sentences cannot be correctly read in Windows due to error in encoding. Since they are few, we will just remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e79887d2d164d269e40ff0225e94ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10944.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "txt_content = {}\n",
    "errors = []\n",
    "for name, path in tqdm(list(zip(all_files_names, all_files_paths))):\n",
    "    with open(path, \"r\") as txt:\n",
    "        try:\n",
    "            txt_content[name] = txt.readline().replace(\",\", \"\")\n",
    "        except Exception as ex:\n",
    "            errors.append((name, str(ex)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_list = [err[0] for err in errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(txt_content, orient='index').reset_index()\n",
    "df.columns = [\"file_id\",\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = pd.read_csv('hate-speech-dataset/annotations_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = ann[~ann['file_id'].isin(errors_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(left=ann, right=df, left_on='file_id', right_on='file_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['noHate', 'hate', 'idk/skip', 'relation'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[(data[\"label\"] != \"relation\") & (data[\"label\"] != \"idk/skip\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"file_id\", \"user_id\", \"subforum_id\", \"num_contexts\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data.apply(lambda x: 0 if x['label'] == \"noHate\" else 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>As of March 13th  2014  the booklet had been d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>In order to help increase the booklets downloa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>( Simply copy and paste the following text int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Click below for a FREE download of a colorfull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  As of March 13th  2014  the booklet had been d...\n",
       "1      0  In order to help increase the booklets downloa...\n",
       "2      0  ( Simply copy and paste the following text int...\n",
       "3      1  Click below for a FREE download of a colorfull...\n",
       "4      0  Click on the `` DOWNLOAD ( 7.42 MB ) '' green ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Removing links, tags, numbers and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text):\n",
    "    cList = {\n",
    "        \"n't\": \" not\",\n",
    "        \"/TD\": \" \",\n",
    "        \" PM \": \" personal message \",\n",
    "        \" pm \": \" personal message \",\n",
    "        \"PM \": \"personal message \",\n",
    "        \" Donot \": \" do not \",\n",
    "        \" MB \": \" megabytes \",\n",
    "    }\n",
    "    \n",
    "    c_re = re.compile(\"(%s)\" % \"|\".join(cList.keys()))\n",
    "\n",
    "    return c_re.sub(lambda match: cList[match.group(0)], text)\n",
    "\n",
    "def full_text_clean(text):\n",
    "    aa = expand_contractions(text)\n",
    "    \n",
    "    bb = pproc.clean(\n",
    "        clean(pproc.clean(aa),\n",
    "              fix_unicode=True,               # fix various unicode errors\n",
    "              to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "              lower=True,                     # lowercase text\n",
    "              no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "              no_urls=True,                  # replace all URLs with a special token\n",
    "              no_emails=True,                # replace all email addresses with a special token\n",
    "              no_phone_numbers=False,         # replace all phone numbers with a special token\n",
    "              no_numbers=False,               # replace all numbers with a special token\n",
    "              no_digits=False,                # replace all digits with a special token\n",
    "              no_currency_symbols=False,      # replace all currency symbols with a special token\n",
    "              no_punct=True,                 # remove punctuations\n",
    "              replace_with_url=\" \",\n",
    "              replace_with_email=\" \",\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    swords = stopwords.words(\"english\")\n",
    "    swords.extend(string.punctuation)\n",
    "\n",
    "    cc = (\n",
    "        bb.lower()\n",
    "        .replace(r\"(@[a-z0-9]+)\\w+\", \" \")\n",
    "        .replace(r\"http\\S+\", \" \")\n",
    "        .replace(r\"www\\S+\", \" \")\n",
    "        .replace(r\"com/watch\", \" \")\n",
    "        .replace(r\"\\S*[.,:;!?-]\\S*[^\\s\\.,:;!?-]\", \" \")\n",
    "        .replace(r\" th \", \" \")\n",
    "        .replace(r\"\\w*\\d\\w*\", \" \")\n",
    "        .replace(r\"rlm\", \" \")\n",
    "        .replace(r\"pttm\", \" \")\n",
    "        .replace(r\"ghlight\", \" \")\n",
    "        .replace(r\"[0-9]+(?:st| st|nd| nd|rd| rd|th| th)\", \" \")\n",
    "        .replace(r\"([^a-z \\t])\", \" \")\n",
    "        .replace(r\" +\", \" \")\n",
    "        )\n",
    "    \n",
    "    cc = \" \".join([i for i in cc.split() if not i in swords])\n",
    "    \n",
    "    return cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06020fe5e2434b00a5221594ea289b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10694.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['text_clean'] = data[\"text\"].progress_apply(lambda x: full_text_clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>As of March 13th  2014  the booklet had been d...</td>\n",
       "      <td>march booklet downloaded times counting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>In order to help increase the booklets downloa...</td>\n",
       "      <td>order help increase booklets downloads would g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>( Simply copy and paste the following text int...</td>\n",
       "      <td>simply copy paste following text youtube video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Click below for a FREE download of a colorfull...</td>\n",
       "      <td>click free download colorfully illustrated pag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...</td>\n",
       "      <td>click download megabytes green banner link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      0  As of March 13th  2014  the booklet had been d...   \n",
       "1      0  In order to help increase the booklets downloa...   \n",
       "2      0  ( Simply copy and paste the following text int...   \n",
       "3      1  Click below for a FREE download of a colorfull...   \n",
       "4      0  Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...   \n",
       "\n",
       "                                          text_clean  \n",
       "0            march booklet downloaded times counting  \n",
       "1  order help increase booklets downloads would g...  \n",
       "2  simply copy paste following text youtube video...  \n",
       "3  click free download colorfully illustrated pag...  \n",
       "4         click download megabytes green banner link  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_count_before'] = data['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_count'] = data['text_clean'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_cleaning'] = data['word_count_before'] - data['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_cleaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10694.000000</td>\n",
       "      <td>10694.000000</td>\n",
       "      <td>10694.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.636993</td>\n",
       "      <td>8.184215</td>\n",
       "      <td>9.452777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.349767</td>\n",
       "      <td>6.690266</td>\n",
       "      <td>7.413768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>343.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>202.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_count_before    word_count  word_cleaning\n",
       "count       10694.000000  10694.000000   10694.000000\n",
       "mean           17.636993      8.184215       9.452777\n",
       "std            13.349767      6.690266       7.413768\n",
       "min             1.000000      0.000000       0.000000\n",
       "25%             9.000000      4.000000       5.000000\n",
       "50%            15.000000      7.000000       8.000000\n",
       "75%            24.000000     11.000000      13.000000\n",
       "max           343.000000    141.000000     202.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['word_count_before','word_count','word_cleaning']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['word_count'] > 0, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Lemmatizer and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = nlp.pipe(data['text_clean'], n_process=2, batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c0aa34a5c94f05bd1ec8a196ba8a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "docs = [x for x in tqdm(pipe)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['spacy_doc'] = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73e2e9fd77442dca08621659b445c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10547.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['POS_spacy'] = data['spacy_doc'].progress_apply(lambda x: [(y.text, y.pos_) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd2fe168e3f4b5fbe289cba566b5f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10547.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['lemmatized'] = data['spacy_doc'].progress_apply(lambda x: \" \".join([y.lemma_ for y in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc67a2e04e44d1a9c49813a19df1f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10547.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['tokens'] = data['spacy_doc'].progress_apply(lambda x: [y.text for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758212c089b444b380cacb07a3841b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10547.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['language'] = data['spacy_doc'].progress_apply(lambda x: set([y.lang_ for y in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 10547}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = {}\n",
    "for line in data['language']:\n",
    "    if len(line) in length:\n",
    "        length[len(line)] += 1\n",
    "    else:\n",
    "        length[len(line)] = 1\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37bd3347e4c548549176e134f966169f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10547.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['language'] = data['language'].progress_apply(lambda x: list(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['language'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text_pos(x):\n",
    "    final_pos_text = []\n",
    "    for elem in x:\n",
    "        for pos in pos_list:\n",
    "            if elem[1] == pos:\n",
    "                final_pos_text.append(elem[0])\n",
    "    \n",
    "    return \" \".join(final_pos_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"NOUN\"]\n",
    "data[\"NOUN\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['NOUN_count'] = data['NOUN'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"PROPN\"]\n",
    "data[\"PROPN\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['PROPN_count'] = data['PROPN'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"VERB\"]\n",
    "data[\"VERB\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['VERB_count'] = data['VERB'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"ADJ\"]\n",
    "data[\"ADJ\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['ADJ_count'] = data['ADJ'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"ADV\"]\n",
    "data[\"ADV\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['ADV_count'] = data['ADV'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"PRON\"]\n",
    "data[\"PRON\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['PRON_count'] = data['PRON'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"SCONJ\"]\n",
    "data[\"SCONJ\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['SCONJ_count'] = data['SCONJ'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"INTJ\"]\n",
    "data[\"INTJ\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['INTJ_count'] = data['SCONJ'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_cleaning</th>\n",
       "      <th>spacy_doc</th>\n",
       "      <th>POS_spacy</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>tokens</th>\n",
       "      <th>...</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADJ_count</th>\n",
       "      <th>ADV</th>\n",
       "      <th>ADV_count</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRON_count</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SCONJ_count</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>INTJ_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>As of March 13th  2014  the booklet had been d...</td>\n",
       "      <td>march booklet downloaded times counting</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>(march, booklet, downloaded, times, counting)</td>\n",
       "      <td>[(march, PROPN), (booklet, PROPN), (downloaded...</td>\n",
       "      <td>march booklet download time count</td>\n",
       "      <td>[march, booklet, downloaded, times, counting]</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>In order to help increase the booklets downloa...</td>\n",
       "      <td>order help increase booklets downloads would g...</td>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>(order, help, increase, booklets, downloads, w...</td>\n",
       "      <td>[(order, NOUN), (help, VERB), (increase, VERB)...</td>\n",
       "      <td>order help increase booklet download would gre...</td>\n",
       "      <td>[order, help, increase, booklets, downloads, w...</td>\n",
       "      <td>...</td>\n",
       "      <td>great youtube</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>( Simply copy and paste the following text int...</td>\n",
       "      <td>simply copy paste following text youtube video...</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>(simply, copy, paste, following, text, youtube...</td>\n",
       "      <td>[(simply, ADV), (copy, VERB), (paste, NOUN), (...</td>\n",
       "      <td>simply copy paste follow text youtube videos d...</td>\n",
       "      <td>[simply, copy, paste, following, text, youtube...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>simply</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Click below for a FREE download of a colorfull...</td>\n",
       "      <td>click free download colorfully illustrated pag...</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>(click, free, download, colorfully, illustrate...</td>\n",
       "      <td>[(click, VERB), (free, ADJ), (download, NOUN),...</td>\n",
       "      <td>click free download colorfully illustrate page...</td>\n",
       "      <td>[click, free, download, colorfully, illustrate...</td>\n",
       "      <td>...</td>\n",
       "      <td>free intentional western</td>\n",
       "      <td>3</td>\n",
       "      <td>colorfully</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...</td>\n",
       "      <td>click download megabytes green banner link</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>(click, download, megabytes, green, banner, link)</td>\n",
       "      <td>[(click, VERB), (download, PROPN), (megabytes,...</td>\n",
       "      <td>click download megabyte green banner link</td>\n",
       "      <td>[click, download, megabytes, green, banner, link]</td>\n",
       "      <td>...</td>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      0  As of March 13th  2014  the booklet had been d...   \n",
       "1      0  In order to help increase the booklets downloa...   \n",
       "2      0  ( Simply copy and paste the following text int...   \n",
       "3      1  Click below for a FREE download of a colorfull...   \n",
       "4      0  Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...   \n",
       "\n",
       "                                          text_clean  word_count_before  \\\n",
       "0            march booklet downloaded times counting                 16   \n",
       "1  order help increase booklets downloads would g...                 34   \n",
       "2  simply copy paste following text youtube video...                 15   \n",
       "3  click free download colorfully illustrated pag...                 22   \n",
       "4         click download megabytes green banner link                 14   \n",
       "\n",
       "   word_count  word_cleaning  \\\n",
       "0           5             11   \n",
       "1          19             15   \n",
       "2           9              6   \n",
       "3          12             10   \n",
       "4           6              8   \n",
       "\n",
       "                                           spacy_doc  \\\n",
       "0      (march, booklet, downloaded, times, counting)   \n",
       "1  (order, help, increase, booklets, downloads, w...   \n",
       "2  (simply, copy, paste, following, text, youtube...   \n",
       "3  (click, free, download, colorfully, illustrate...   \n",
       "4  (click, download, megabytes, green, banner, link)   \n",
       "\n",
       "                                           POS_spacy  \\\n",
       "0  [(march, PROPN), (booklet, PROPN), (downloaded...   \n",
       "1  [(order, NOUN), (help, VERB), (increase, VERB)...   \n",
       "2  [(simply, ADV), (copy, VERB), (paste, NOUN), (...   \n",
       "3  [(click, VERB), (free, ADJ), (download, NOUN),...   \n",
       "4  [(click, VERB), (download, PROPN), (megabytes,...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0                  march booklet download time count   \n",
       "1  order help increase booklet download would gre...   \n",
       "2  simply copy paste follow text youtube videos d...   \n",
       "3  click free download colorfully illustrate page...   \n",
       "4          click download megabyte green banner link   \n",
       "\n",
       "                                              tokens  ...  \\\n",
       "0      [march, booklet, downloaded, times, counting]  ...   \n",
       "1  [order, help, increase, booklets, downloads, w...  ...   \n",
       "2  [simply, copy, paste, following, text, youtube...  ...   \n",
       "3  [click, free, download, colorfully, illustrate...  ...   \n",
       "4  [click, download, megabytes, green, banner, link]  ...   \n",
       "\n",
       "                        ADJ ADJ_count         ADV ADV_count  PRON PRON_count  \\\n",
       "0                                   0                     0                0   \n",
       "1             great youtube         2                     0                0   \n",
       "2                                   0      simply         1                0   \n",
       "3  free intentional western         3  colorfully         1                0   \n",
       "4                     green         1                     0                0   \n",
       "\n",
       "   SCONJ SCONJ_count  INTJ INTJ_count  \n",
       "0                  0                0  \n",
       "1                  0                0  \n",
       "2                  0                0  \n",
       "3                  0                0  \n",
       "4                  0                0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10547 entries, 0 to 10925\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   label              10547 non-null  int64 \n",
      " 1   text               10547 non-null  object\n",
      " 2   text_clean         10547 non-null  object\n",
      " 3   word_count_before  10547 non-null  int64 \n",
      " 4   word_count         10547 non-null  int64 \n",
      " 5   word_cleaning      10547 non-null  int64 \n",
      " 6   spacy_doc          10547 non-null  object\n",
      " 7   POS_spacy          10547 non-null  object\n",
      " 8   lemmatized         10547 non-null  object\n",
      " 9   tokens             10547 non-null  object\n",
      " 10  language           10547 non-null  object\n",
      " 11  NOUN               10547 non-null  object\n",
      " 12  NOUN_count         10547 non-null  int64 \n",
      " 13  PROPN              10547 non-null  object\n",
      " 14  PROPN_count        10547 non-null  int64 \n",
      " 15  VERB               10547 non-null  object\n",
      " 16  VERB_count         10547 non-null  int64 \n",
      " 17  ADJ                10547 non-null  object\n",
      " 18  ADJ_count          10547 non-null  int64 \n",
      " 19  ADV                10547 non-null  object\n",
      " 20  ADV_count          10547 non-null  int64 \n",
      " 21  PRON               10547 non-null  object\n",
      " 22  PRON_count         10547 non-null  int64 \n",
      " 23  SCONJ              10547 non-null  object\n",
      " 24  SCONJ_count        10547 non-null  int64 \n",
      " 25  INTJ               10547 non-null  object\n",
      " 26  INTJ_count         10547 non-null  int64 \n",
      "dtypes: int64(12), object(15)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"spacy_doc\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"label\", \"text\", \"text_clean\", \"POS_spacy\", \"lemmatized\", \"tokens\", \"language\", \"word_count_before\",\"word_count\", \"word_cleaning\",\"NOUN\", \"NOUN_count\", \"PROPN\", \"PROPN_count\", \"VERB\", \"VERB_count\", \"ADJ\", \"ADJ_count\", \"ADV\", \"ADV_count\", \"PRON\", \"PRON_count\", \"SCONJ\", \"SCONJ_count\", \"INTJ\", \"INTJ_count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10547 entries, 0 to 10925\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   label              10547 non-null  int64 \n",
      " 1   text               10547 non-null  object\n",
      " 2   text_clean         10547 non-null  object\n",
      " 3   POS_spacy          10547 non-null  object\n",
      " 4   lemmatized         10547 non-null  object\n",
      " 5   tokens             10547 non-null  object\n",
      " 6   language           10547 non-null  object\n",
      " 7   word_count_before  10547 non-null  int64 \n",
      " 8   word_count         10547 non-null  int64 \n",
      " 9   word_cleaning      10547 non-null  int64 \n",
      " 10  NOUN               10547 non-null  object\n",
      " 11  NOUN_count         10547 non-null  int64 \n",
      " 12  PROPN              10547 non-null  object\n",
      " 13  PROPN_count        10547 non-null  int64 \n",
      " 14  VERB               10547 non-null  object\n",
      " 15  VERB_count         10547 non-null  int64 \n",
      " 16  ADJ                10547 non-null  object\n",
      " 17  ADJ_count          10547 non-null  int64 \n",
      " 18  ADV                10547 non-null  object\n",
      " 19  ADV_count          10547 non-null  int64 \n",
      " 20  PRON               10547 non-null  object\n",
      " 21  PRON_count         10547 non-null  int64 \n",
      " 22  SCONJ              10547 non-null  object\n",
      " 23  SCONJ_count        10547 non-null  int64 \n",
      " 24  INTJ               10547 non-null  object\n",
      " 25  INTJ_count         10547 non-null  int64 \n",
      "dtypes: int64(12), object(14)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
