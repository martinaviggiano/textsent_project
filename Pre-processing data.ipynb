{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA IMPORT\n",
    "Hate speech dataset from a white supremacist forum:  https://github.com/Vicomtech/hate-speech-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import ntpath\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import nltk.sentiment.vader as vd\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import download\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    plot_confusion_matrix,\n",
    "    plot_precision_recall_curve,\n",
    "    plot_roc_curve,\n",
    ")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import sklearn as sk\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as VS\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "import preprocessor as pproc\n",
    "from cleantext import clean\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\tqdm\\std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\marti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_paths = glob.glob(\"hate-speech-dataset/all_files/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_paths = [f for f in all_files_paths if os.path.isfile(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_names = [str(ntpath.basename(f)).replace(\".txt\", \"\") for f in all_files_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Error removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35691d5c4f94d85a529ed81d92def8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10944.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "txt_content = {}\n",
    "errors = []\n",
    "for name, path in tqdm(list(zip(all_files_names, all_files_paths))):\n",
    "    with open(path, \"r\") as txt:\n",
    "        try:\n",
    "            txt_content[name] = txt.readline().replace(\",\", \"\")\n",
    "        except Exception as ex:\n",
    "            errors.append((name, str(ex)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_list = [err[0] for err in errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(txt_content, orient='index').reset_index()\n",
    "df.columns = [\"file_id\",\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = pd.read_csv('hate-speech-dataset/annotations_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = ann[~ann['file_id'].isin(errors_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>subforum_id</th>\n",
       "      <th>num_contexts</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12834217_1</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>As of March 13th  2014  the booklet had been d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12834217_2</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>In order to help increase the booklets downloa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12834217_3</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>( Simply copy and paste the following text int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12834217_4</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>hate</td>\n",
       "      <td>Click below for a FREE download of a colorfull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12834217_5</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_id  user_id  subforum_id  num_contexts   label  \\\n",
       "0  12834217_1   572066         1346             0  noHate   \n",
       "1  12834217_2   572066         1346             0  noHate   \n",
       "2  12834217_3   572066         1346             0  noHate   \n",
       "3  12834217_4   572066         1346             0    hate   \n",
       "4  12834217_5   572066         1346             0  noHate   \n",
       "\n",
       "                                                text  \n",
       "0  As of March 13th  2014  the booklet had been d...  \n",
       "1  In order to help increase the booklets downloa...  \n",
       "2  ( Simply copy and paste the following text int...  \n",
       "3  Click below for a FREE download of a colorfull...  \n",
       "4  Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(left=ann, right=df, left_on='file_id', right_on='file_id')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['noHate', 'hate', 'idk/skip', 'relation'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[(data[\"label\"] != \"relation\") & (data[\"label\"] != \"idk/skip\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"file_id\", \"user_id\", \"subforum_id\", \"num_contexts\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data.apply(lambda x: 0 if x['label'] == \"noHate\" else 1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Removing links, tags, numbers and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_text_clean(text):\n",
    "    cList = {\n",
    "        \"n't\": \" not\",\n",
    "        \"/TD\": \" \",\n",
    "        \" PM \": \" personal message \",\n",
    "        \" pm \": \" personal message \",\n",
    "        \"PM \": \"personal message \",\n",
    "        \" Donot \": \" do not \",\n",
    "        \" MB \": \" megabytes \",\n",
    "    }\n",
    "\n",
    "    c_re = re.compile(\"(%s)\" % \"|\".join(cList.keys()))\n",
    "    \n",
    "    def expand_contractions(text, c_re=c_re):\n",
    "        def replace(match):\n",
    "            return cList[match.group(0)]\n",
    "\n",
    "        return c_re.sub(replace, text)\n",
    "    \n",
    "    qualcosa = expand_contractions(text)\n",
    "    \n",
    "    qualcosaltro = pproc.clean(\n",
    "            clean(\n",
    "                pproc.clean(qualcosa),\n",
    "                fix_unicode=True,  # fix various unicode errors\n",
    "                to_ascii=True,  # transliterate to closest ASCII representation\n",
    "                lower=True,  # lowercase text\n",
    "                no_line_breaks=True,  # fully strip line breaks as opposed to only normalizing them\n",
    "                no_urls=True,  # replace all URLs with a special token\n",
    "                no_emails=True,  # replace all email addresses with a special token\n",
    "                no_phone_numbers=True,  # replace all phone numbers with a special token\n",
    "                no_numbers=True,  # replace all numbers with a special token\n",
    "                no_digits=True,  # replace all digits with a special token\n",
    "                no_currency_symbols=True,  # replace all currency symbols with a special token\n",
    "                no_punct=True,\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    swords = set().union(stopwords.words(\"english\"), string.punctuation)\n",
    "\n",
    "    altroancora = (\n",
    "        qualcosaltro\n",
    "        .lower()\n",
    "        .replace(r\"(@[a-z0-9]+)\\w+\", \" \")\n",
    "        .replace(r\"http\\S+\", \"\")\n",
    "        .replace(r\"www\\S+\", \" \")\n",
    "        .replace(r\"com/watch\", \" \")\n",
    "        .replace(r\"\\S*[.,:;!?-]\\S*[^\\s\\.,:;!?-]\", \" \")\n",
    "        .replace(r\" th \", \" \")\n",
    "        .replace(r\" th \", \" \")\n",
    "        .replace(r\"\\w*\\d\\w*\", \" \")\n",
    "        .replace(r\"rlm\", \" \")\n",
    "        .replace(r\"pttm\", \" \")\n",
    "        .replace(r\"ghlight\", \" \")\n",
    "        .replace(r\"[0-9]+(?:st| st|nd| nd|rd| rd|th| th)\", \"\")\n",
    "        .replace(r\"([^a-z \\t])\", \" \")\n",
    "        .replace(r\" +\", \" \")\n",
    "        )\n",
    "    \n",
    "    altroancora = \" \".join([i for i in altroancora.split() if not i in swords])\n",
    "    \n",
    "    return altroancora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_clean'] = [full_text_clean(text) for text in data['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>As of March 13th  2014  the booklet had been d...</td>\n",
       "      <td>march booklet downloaded times counting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>In order to help increase the booklets downloa...</td>\n",
       "      <td>order help increase booklets downloads would g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>( Simply copy and paste the following text int...</td>\n",
       "      <td>simply copy paste following text youtube video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Click below for a FREE download of a colorfull...</td>\n",
       "      <td>click free download colorfully illustrated pag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...</td>\n",
       "      <td>click download megabytes green banner link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      0  As of March 13th  2014  the booklet had been d...   \n",
       "1      0  In order to help increase the booklets downloa...   \n",
       "2      0  ( Simply copy and paste the following text int...   \n",
       "3      1  Click below for a FREE download of a colorfull...   \n",
       "4      0  Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...   \n",
       "\n",
       "                                          text_clean  \n",
       "0            march booklet downloaded times counting  \n",
       "1  order help increase booklets downloads would g...  \n",
       "2  simply copy paste following text youtube video...  \n",
       "3  click free download colorfully illustrated pag...  \n",
       "4         click download megabytes green banner link  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_count_before'] = data['text'].apply(lambda x: len(x.split())) # Number of words in the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_count'] = data['text_clean'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_cleaning'] = data['word_count_before'] - data['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_cleaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10694.000000</td>\n",
       "      <td>10694.000000</td>\n",
       "      <td>10694.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.636993</td>\n",
       "      <td>8.208809</td>\n",
       "      <td>9.428184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.349767</td>\n",
       "      <td>6.727260</td>\n",
       "      <td>7.383386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>343.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>202.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_count_before    word_count  word_cleaning\n",
       "count       10694.000000  10694.000000   10694.000000\n",
       "mean           17.636993      8.208809       9.428184\n",
       "std            13.349767      6.727260       7.383386\n",
       "min             1.000000      0.000000       0.000000\n",
       "25%             9.000000      4.000000       5.000000\n",
       "50%            15.000000      7.000000       8.000000\n",
       "75%            24.000000     11.000000      13.000000\n",
       "max           343.000000    141.000000     202.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['word_count_before','word_count','word_cleaning']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['word_count'] > 0, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Lemmatizer and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp.pipe(data['text_clean'], n_process=2, batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de98f4894c8492bb1b02788ec92912a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['spacy_doc'] = [x for x in tqdm(docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31dfa6177060414dacda7155f9022854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10562.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['POS_spacy'] = data['spacy_doc'].progress_apply(lambda x: [(y.text, y.pos_) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9abe9ee8754cfdbfbd3377891bc746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10562.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['lemmatized'] = data['spacy_doc'].progress_apply(lambda x: \" \".join([y.lemma_ for y in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d6d7d8357d4541a64736dd2996495b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10562.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['tokens'] = data['spacy_doc'].progress_apply(lambda x: [y.text for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25664fb123604823b7a026755938639c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10562.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['language'] = data['spacy_doc'].progress_apply(lambda x: set([y.lang_ for y in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 10562}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = {}\n",
    "for line in data['language']:\n",
    "    if len(line) in length:\n",
    "        length[len(line)] += 1\n",
    "    else:\n",
    "        length[len(line)] = 1\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a29c1807d7a45c9a1c35b891effa354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10562.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['language'] = data['language'].progress_apply(lambda x: list(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['language'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text_pos(x):\n",
    "    final_pos_text = []\n",
    "    for elem in x:\n",
    "        for pos in pos_list:\n",
    "            if elem[1] == pos:\n",
    "                final_pos_text.append(elem[0])\n",
    "    \n",
    "    return \" \".join(final_pos_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"NOUN\"]\n",
    "data[\"NOUN\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['NOUN_count'] = data['NOUN'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"PROPN\"]\n",
    "data[\"PROPN\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['PROPN_count'] = data['PROPN'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"VERB\"]\n",
    "data[\"VERB\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['VERB_count'] = data['VERB'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"ADJ\"]\n",
    "data[\"ADJ\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['ADJ_count'] = data['ADJ'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"ADV\"]\n",
    "data[\"ADV\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['ADV_count'] = data['ADV'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"PRON\"]\n",
    "data[\"PRON\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['PRON_count'] = data['PRON'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"SCONJ\"]\n",
    "data[\"SCONJ\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['SCONJ_count'] = data['SCONJ'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"INTJ\"]\n",
    "data[\"INTJ\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['INTJ_count'] = data['SCONJ'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_cleaning</th>\n",
       "      <th>spacy_doc</th>\n",
       "      <th>POS_spacy</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>tokens</th>\n",
       "      <th>...</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADJ_count</th>\n",
       "      <th>ADV</th>\n",
       "      <th>ADV_count</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRON_count</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SCONJ_count</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>INTJ_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>As of March 13th  2014  the booklet had been d...</td>\n",
       "      <td>march booklet downloaded times counting</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>(march, booklet, downloaded, times, counting)</td>\n",
       "      <td>[(march, PROPN), (booklet, PROPN), (downloaded...</td>\n",
       "      <td>march booklet download time count</td>\n",
       "      <td>[march, booklet, downloaded, times, counting]</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>In order to help increase the booklets downloa...</td>\n",
       "      <td>order help increase booklets downloads would g...</td>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>(order, help, increase, booklets, downloads, w...</td>\n",
       "      <td>[(order, NOUN), (help, VERB), (increase, VERB)...</td>\n",
       "      <td>order help increase booklet download would gre...</td>\n",
       "      <td>[order, help, increase, booklets, downloads, w...</td>\n",
       "      <td>...</td>\n",
       "      <td>great youtube</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>( Simply copy and paste the following text int...</td>\n",
       "      <td>simply copy paste following text youtube video...</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>(simply, copy, paste, following, text, youtube...</td>\n",
       "      <td>[(simply, ADV), (copy, VERB), (paste, NOUN), (...</td>\n",
       "      <td>simply copy paste follow text youtube videos d...</td>\n",
       "      <td>[simply, copy, paste, following, text, youtube...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>simply</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Click below for a FREE download of a colorfull...</td>\n",
       "      <td>click free download colorfully illustrated pag...</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>(click, free, download, colorfully, illustrate...</td>\n",
       "      <td>[(click, VERB), (free, ADJ), (download, NOUN),...</td>\n",
       "      <td>click free download colorfully illustrate page...</td>\n",
       "      <td>[click, free, download, colorfully, illustrate...</td>\n",
       "      <td>...</td>\n",
       "      <td>free intentional western</td>\n",
       "      <td>3</td>\n",
       "      <td>colorfully</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...</td>\n",
       "      <td>click download megabytes green banner link</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>(click, download, megabytes, green, banner, link)</td>\n",
       "      <td>[(click, VERB), (download, PROPN), (megabytes,...</td>\n",
       "      <td>click download megabyte green banner link</td>\n",
       "      <td>[click, download, megabytes, green, banner, link]</td>\n",
       "      <td>...</td>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      0  As of March 13th  2014  the booklet had been d...   \n",
       "1      0  In order to help increase the booklets downloa...   \n",
       "2      0  ( Simply copy and paste the following text int...   \n",
       "3      1  Click below for a FREE download of a colorfull...   \n",
       "4      0  Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...   \n",
       "\n",
       "                                          text_clean  word_count_before  \\\n",
       "0            march booklet downloaded times counting                 16   \n",
       "1  order help increase booklets downloads would g...                 34   \n",
       "2  simply copy paste following text youtube video...                 15   \n",
       "3  click free download colorfully illustrated pag...                 22   \n",
       "4         click download megabytes green banner link                 14   \n",
       "\n",
       "   word_count  word_cleaning  \\\n",
       "0           5             11   \n",
       "1          19             15   \n",
       "2           9              6   \n",
       "3          12             10   \n",
       "4           6              8   \n",
       "\n",
       "                                           spacy_doc  \\\n",
       "0      (march, booklet, downloaded, times, counting)   \n",
       "1  (order, help, increase, booklets, downloads, w...   \n",
       "2  (simply, copy, paste, following, text, youtube...   \n",
       "3  (click, free, download, colorfully, illustrate...   \n",
       "4  (click, download, megabytes, green, banner, link)   \n",
       "\n",
       "                                           POS_spacy  \\\n",
       "0  [(march, PROPN), (booklet, PROPN), (downloaded...   \n",
       "1  [(order, NOUN), (help, VERB), (increase, VERB)...   \n",
       "2  [(simply, ADV), (copy, VERB), (paste, NOUN), (...   \n",
       "3  [(click, VERB), (free, ADJ), (download, NOUN),...   \n",
       "4  [(click, VERB), (download, PROPN), (megabytes,...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0                  march booklet download time count   \n",
       "1  order help increase booklet download would gre...   \n",
       "2  simply copy paste follow text youtube videos d...   \n",
       "3  click free download colorfully illustrate page...   \n",
       "4          click download megabyte green banner link   \n",
       "\n",
       "                                              tokens  ...  \\\n",
       "0      [march, booklet, downloaded, times, counting]  ...   \n",
       "1  [order, help, increase, booklets, downloads, w...  ...   \n",
       "2  [simply, copy, paste, following, text, youtube...  ...   \n",
       "3  [click, free, download, colorfully, illustrate...  ...   \n",
       "4  [click, download, megabytes, green, banner, link]  ...   \n",
       "\n",
       "                        ADJ ADJ_count         ADV ADV_count  PRON PRON_count  \\\n",
       "0                                   0                     0                0   \n",
       "1             great youtube         2                     0                0   \n",
       "2                                   0      simply         1                0   \n",
       "3  free intentional western         3  colorfully         1                0   \n",
       "4                     green         1                     0                0   \n",
       "\n",
       "   SCONJ SCONJ_count  INTJ INTJ_count  \n",
       "0                  0                0  \n",
       "1                  0                0  \n",
       "2                  0                0  \n",
       "3                  0                0  \n",
       "4                  0                0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
