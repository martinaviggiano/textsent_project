{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA IMPORT\n",
    "Hate speech dataset from a white supremacist forum:  https://github.com/Vicomtech/hate-speech-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import ntpath\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import nltk.sentiment.vader as vd\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "from nltk import download\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import preprocessor as pproc\n",
    "from cleantext import clean\n",
    "import dataframe_image as dfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\tqdm\\std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\marti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_paths = glob.glob(\"hate-speech-dataset/all_files/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_paths = [f for f in all_files_paths if os.path.isfile(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_names = [str(ntpath.basename(f)).replace(\".txt\", \"\") for f in all_files_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Error removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sentences cannot be correctly read in Windows due to error in encoding. Since they are few, we will just remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99c9948bb804b3ca2ec3fb76316a106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10944.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "txt_content = {}\n",
    "errors = []\n",
    "for name, path in tqdm(list(zip(all_files_names, all_files_paths))):\n",
    "    with open(path, \"r\") as txt:\n",
    "        try:\n",
    "            txt_content[name] = txt.readline().replace(\",\", \"\")\n",
    "        except Exception as ex:\n",
    "            errors.append((name, str(ex)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_list = [err[0] for err in errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(txt_content, orient='index').reset_index()\n",
    "df.columns = [\"file_id\",\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = pd.read_csv('hate-speech-dataset/annotations_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = ann[~ann['file_id'].isin(errors_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(left=ann, right=df, left_on='file_id', right_on='file_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['noHate', 'hate', 'idk/skip', 'relation'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[(data[\"label\"] != \"relation\") & (data[\"label\"] != \"idk/skip\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"file_id\", \"user_id\", \"subforum_id\", \"num_contexts\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data.apply(lambda x: 0 if x['label'] == \"noHate\" else 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>As of March 13th  2014  the booklet had been d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>In order to help increase the booklets downloa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>( Simply copy and paste the following text int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Click below for a FREE download of a colorfull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  As of March 13th  2014  the booklet had been d...\n",
       "1      0  In order to help increase the booklets downloa...\n",
       "2      0  ( Simply copy and paste the following text int...\n",
       "3      1  Click below for a FREE download of a colorfull...\n",
       "4      0  Click on the `` DOWNLOAD ( 7.42 MB ) '' green ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Removing links, tags, numbers and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text):\n",
    "    cList = {\n",
    "        \"n't\": \" not\",\n",
    "        \"/TD\": \" \",\n",
    "        \" PM \": \" personal message \",\n",
    "        \" pm \": \" personal message \",\n",
    "        \"PM \": \"personal message \",\n",
    "        \" Donot \": \" do not \",\n",
    "        \" MB \": \" megabytes \",\n",
    "        \"I'm\" : \"I am\",\n",
    "        \" 've \" : \" have \",\n",
    "        \" 're \" : \" are \",\n",
    "        \" 'll \" : \" will \"\n",
    "    }\n",
    "    \n",
    "    c_re = re.compile(\"(%s)\" % \"|\".join(cList.keys()))\n",
    "\n",
    "    return c_re.sub(lambda match: cList[match.group(0)], text)\n",
    "\n",
    "def full_text_clean(text):\n",
    "    aa = expand_contractions(text)\n",
    "    \n",
    "    bb = pproc.clean(\n",
    "        clean(pproc.clean(aa),\n",
    "              fix_unicode=True,               # fix various unicode errors\n",
    "              to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "              lower=True,                     # lowercase text\n",
    "              no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "              no_urls=True,                  # replace all URLs with a special token\n",
    "              no_emails=True,                # replace all email addresses with a special token\n",
    "              no_phone_numbers=False,         # replace all phone numbers with a special token\n",
    "              no_numbers=False,               # replace all numbers with a special token\n",
    "              no_digits=False,                # replace all digits with a special token\n",
    "              no_currency_symbols=False,      # replace all currency symbols with a special token\n",
    "              no_punct=True,                 # remove punctuations\n",
    "              replace_with_url=\" \",\n",
    "              replace_with_email=\" \",\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    swords = string.punctuation\n",
    "\n",
    "    cc = (\n",
    "        bb.lower()\n",
    "        .replace(r\"(@[a-z0-9]+)\\w+\", \" \")\n",
    "        .replace(r\"www\\S+\", \" \")\n",
    "        .replace(r\"com/watch\", \" \")\n",
    "        .replace(r\"\\S*[.,:;!?-]\\S*[^\\s\\.,:;!?-]\", \" \")\n",
    "        .replace(r\" th \", \" \")\n",
    "        .replace(r\"\\w*\\d\\w*\", \" \")\n",
    "        .replace(r\"rlm\", \" \")\n",
    "        .replace(r\"pttm\", \" \")\n",
    "        .replace(r\"ghlight\", \" \")\n",
    "        .replace(r\"[0-9]+(?:st| st|nd| nd|rd| rd|th| th)\", \" \")\n",
    "        .replace(r\"([^a-z \\t])\", \" \")\n",
    "        .replace(r\" +\", \" \")\n",
    "        .replace(r\"http\", \" \")\n",
    "        )\n",
    "    \n",
    "    cc = \" \".join([i for i in cc.split() if not i in swords and len(i) >1 ])\n",
    "    \n",
    "    return cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f33baea7b84272a293f7f7696fff6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10694.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['text_clean'] = data[\"text\"].progress_apply(lambda x: full_text_clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>As of March 13th  2014  the booklet had been d...</td>\n",
       "      <td>as of march the booklet had been downloaded ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>In order to help increase the booklets downloa...</td>\n",
       "      <td>in order to help increase the booklets downloa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>( Simply copy and paste the following text int...</td>\n",
       "      <td>simply copy and paste the following text into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Click below for a FREE download of a colorfull...</td>\n",
       "      <td>click below for free download of colorfully il...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...</td>\n",
       "      <td>click on the download megabytes green banner link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      0  As of March 13th  2014  the booklet had been d...   \n",
       "1      0  In order to help increase the booklets downloa...   \n",
       "2      0  ( Simply copy and paste the following text int...   \n",
       "3      1  Click below for a FREE download of a colorfull...   \n",
       "4      0  Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...   \n",
       "\n",
       "                                          text_clean  \n",
       "0  as of march the booklet had been downloaded ov...  \n",
       "1  in order to help increase the booklets downloa...  \n",
       "2  simply copy and paste the following text into ...  \n",
       "3  click below for free download of colorfully il...  \n",
       "4  click on the download megabytes green banner link  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_count_before'] = data['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_count'] = data['text_clean'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_cleaning'] = data['word_count_before'] - data['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_cleaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10694.000000</td>\n",
       "      <td>10694.000000</td>\n",
       "      <td>10694.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.636993</td>\n",
       "      <td>14.966336</td>\n",
       "      <td>2.670656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.349767</td>\n",
       "      <td>11.492576</td>\n",
       "      <td>3.587754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>343.000000</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>108.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_count_before    word_count  word_cleaning\n",
       "count       10694.000000  10694.000000   10694.000000\n",
       "mean           17.636993     14.966336       2.670656\n",
       "std            13.349767     11.492576       3.587754\n",
       "min             1.000000      0.000000      -1.000000\n",
       "25%             9.000000      7.000000       1.000000\n",
       "50%            15.000000     13.000000       2.000000\n",
       "75%            24.000000     21.000000       3.000000\n",
       "max           343.000000    286.000000     108.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_df = data[['word_count_before','word_count','word_cleaning']].describe()\n",
    "word_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_styled = word_count_df\n",
    "dfi.export(df_styled,\"images_d\\word_count_df.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['word_count'] > 0, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Lemmatizer and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = nlp.pipe(data['text_clean'], n_process=2, batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6812e65d8f545b3b62a63cac70c8007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "docs = [x for x in tqdm(pipe)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['spacy_doc'] = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8872b9a4b9c34db58c30383ebdabfedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10570.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['POS_spacy'] = data['spacy_doc'].progress_apply(lambda x: [(y.text, y.pos_) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf07840788e4a77a8b0c9a31989c74c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10570.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['lemmatized'] = data['spacy_doc'].progress_apply(lambda x: \" \".join([y.lemma_ for y in x if len(x)>1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849dfef41fdb4b9588fcbeefc19cd7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10570.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['tokens'] = data['spacy_doc'].progress_apply(lambda x: [y.text for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12bde509bbd4cc3b3d34dfcc1b7f582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10570.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['language'] = data['spacy_doc'].progress_apply(lambda x: set([y.lang_ for y in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 10570}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = {}\n",
    "for line in data['language']:\n",
    "    if len(line) in length:\n",
    "        length[len(line)] += 1\n",
    "    else:\n",
    "        length[len(line)] = 1\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc955c213ce341728b1f9dc41864d820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10570.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data['language'] = data['language'].progress_apply(lambda x: list(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['language'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text_pos(x):\n",
    "    final_pos_text = []\n",
    "    for elem in x:\n",
    "        for pos in pos_list:\n",
    "            if elem[1] == pos:\n",
    "                final_pos_text.append(elem[0])\n",
    "    \n",
    "    return \" \".join(final_pos_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"NOUN\"]\n",
    "data[\"NOUN\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['NOUN_count'] = data['NOUN'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"PROPN\"]\n",
    "data[\"PROPN\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['PROPN_count'] = data['PROPN'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"VERB\"]\n",
    "data[\"VERB\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['VERB_count'] = data['VERB'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"ADJ\"]\n",
    "data[\"ADJ\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['ADJ_count'] = data['ADJ'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"ADV\"]\n",
    "data[\"ADV\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['ADV_count'] = data['ADV'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"PRON\"]\n",
    "data[\"PRON\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['PRON_count'] = data['PRON'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"SCONJ\"]\n",
    "data[\"SCONJ\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['SCONJ_count'] = data['SCONJ'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"INTJ\"]\n",
    "data[\"INTJ\"] = data.apply(lambda x: filter_text_pos(x[\"POS_spacy\"]), axis=1)\n",
    "data['INTJ_count'] = data['SCONJ'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_cleaning</th>\n",
       "      <th>spacy_doc</th>\n",
       "      <th>POS_spacy</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>tokens</th>\n",
       "      <th>...</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADJ_count</th>\n",
       "      <th>ADV</th>\n",
       "      <th>ADV_count</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRON_count</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SCONJ_count</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>INTJ_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>As of March 13th  2014  the booklet had been d...</td>\n",
       "      <td>as of march the booklet had been downloaded ov...</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>(as, of, march, the, booklet, had, been, downl...</td>\n",
       "      <td>[(as, SCONJ), (of, ADP), (march, PROPN), (the,...</td>\n",
       "      <td>as of march the booklet have be download over ...</td>\n",
       "      <td>[as, of, march, the, booklet, had, been, downl...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>as</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>In order to help increase the booklets downloa...</td>\n",
       "      <td>in order to help increase the booklets downloa...</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>(in, order, to, help, increase, the, booklets,...</td>\n",
       "      <td>[(in, ADP), (order, NOUN), (to, PART), (help, ...</td>\n",
       "      <td>in order to help increase the booklet download...</td>\n",
       "      <td>[in, order, to, help, increase, the, booklets,...</td>\n",
       "      <td>...</td>\n",
       "      <td>great uploaded</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>it who</td>\n",
       "      <td>2</td>\n",
       "      <td>if</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>( Simply copy and paste the following text int...</td>\n",
       "      <td>simply copy and paste the following text into ...</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>(simply, copy, and, paste, the, following, tex...</td>\n",
       "      <td>[(simply, ADV), (copy, VERB), (and, CCONJ), (p...</td>\n",
       "      <td>simply copy and paste the follow text into -PR...</td>\n",
       "      <td>[simply, copy, and, paste, the, following, tex...</td>\n",
       "      <td>...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>1</td>\n",
       "      <td>simply</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Click below for a FREE download of a colorfull...</td>\n",
       "      <td>click below for free download of colorfully il...</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>(click, below, for, free, download, of, colorf...</td>\n",
       "      <td>[(click, VERB), (below, ADV), (for, ADP), (fre...</td>\n",
       "      <td>click below for free download of colorfully il...</td>\n",
       "      <td>[click, below, for, free, download, of, colorf...</td>\n",
       "      <td>...</td>\n",
       "      <td>free zionistengineered intentional western</td>\n",
       "      <td>4</td>\n",
       "      <td>below colorfully</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...</td>\n",
       "      <td>click on the download megabytes green banner link</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>(click, on, the, download, megabytes, green, b...</td>\n",
       "      <td>[(click, VERB), (on, ADP), (the, DET), (downlo...</td>\n",
       "      <td>click on the download megabyte green banner link</td>\n",
       "      <td>[click, on, the, download, megabytes, green, b...</td>\n",
       "      <td>...</td>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      0  As of March 13th  2014  the booklet had been d...   \n",
       "1      0  In order to help increase the booklets downloa...   \n",
       "2      0  ( Simply copy and paste the following text int...   \n",
       "3      1  Click below for a FREE download of a colorfull...   \n",
       "4      0  Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...   \n",
       "\n",
       "                                          text_clean  word_count_before  \\\n",
       "0  as of march the booklet had been downloaded ov...                 16   \n",
       "1  in order to help increase the booklets downloa...                 34   \n",
       "2  simply copy and paste the following text into ...                 15   \n",
       "3  click below for free download of colorfully il...                 22   \n",
       "4  click on the download megabytes green banner link                 14   \n",
       "\n",
       "   word_count  word_cleaning  \\\n",
       "0          12              4   \n",
       "1          33              1   \n",
       "2          13              2   \n",
       "3          18              4   \n",
       "4           8              6   \n",
       "\n",
       "                                           spacy_doc  \\\n",
       "0  (as, of, march, the, booklet, had, been, downl...   \n",
       "1  (in, order, to, help, increase, the, booklets,...   \n",
       "2  (simply, copy, and, paste, the, following, tex...   \n",
       "3  (click, below, for, free, download, of, colorf...   \n",
       "4  (click, on, the, download, megabytes, green, b...   \n",
       "\n",
       "                                           POS_spacy  \\\n",
       "0  [(as, SCONJ), (of, ADP), (march, PROPN), (the,...   \n",
       "1  [(in, ADP), (order, NOUN), (to, PART), (help, ...   \n",
       "2  [(simply, ADV), (copy, VERB), (and, CCONJ), (p...   \n",
       "3  [(click, VERB), (below, ADV), (for, ADP), (fre...   \n",
       "4  [(click, VERB), (on, ADP), (the, DET), (downlo...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  as of march the booklet have be download over ...   \n",
       "1  in order to help increase the booklet download...   \n",
       "2  simply copy and paste the follow text into -PR...   \n",
       "3  click below for free download of colorfully il...   \n",
       "4   click on the download megabyte green banner link   \n",
       "\n",
       "                                              tokens  ...  \\\n",
       "0  [as, of, march, the, booklet, had, been, downl...  ...   \n",
       "1  [in, order, to, help, increase, the, booklets,...  ...   \n",
       "2  [simply, copy, and, paste, the, following, tex...  ...   \n",
       "3  [click, below, for, free, download, of, colorf...  ...   \n",
       "4  [click, on, the, download, megabytes, green, b...  ...   \n",
       "\n",
       "                                          ADJ ADJ_count               ADV  \\\n",
       "0                                                     0                     \n",
       "1                              great uploaded         2                     \n",
       "2                                     youtube         1            simply   \n",
       "3  free zionistengineered intentional western         4  below colorfully   \n",
       "4                                       green         1                     \n",
       "\n",
       "  ADV_count    PRON PRON_count  SCONJ SCONJ_count  INTJ INTJ_count  \n",
       "0         0                  0     as           1                1  \n",
       "1         0  it who          2     if           1                1  \n",
       "2         1                  0                  0                0  \n",
       "3         2                  0                  0                0  \n",
       "4         0                  0                  0                0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"spacy_doc\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"label\", \"text\", \"text_clean\", \"POS_spacy\", \"lemmatized\", \"tokens\", \"language\", \"word_count_before\",\"word_count\", \"word_cleaning\",\"NOUN\", \"NOUN_count\", \"PROPN\", \"PROPN_count\", \"VERB\", \"VERB_count\", \"ADJ\", \"ADJ_count\", \"ADV\", \"ADV_count\", \"PRON\", \"PRON_count\", \"SCONJ\", \"SCONJ_count\", \"INTJ\", \"INTJ_count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10570 entries, 0 to 10925\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   label              10570 non-null  int64 \n",
      " 1   text               10570 non-null  object\n",
      " 2   text_clean         10570 non-null  object\n",
      " 3   POS_spacy          10570 non-null  object\n",
      " 4   lemmatized         10570 non-null  object\n",
      " 5   tokens             10570 non-null  object\n",
      " 6   language           10570 non-null  object\n",
      " 7   word_count_before  10570 non-null  int64 \n",
      " 8   word_count         10570 non-null  int64 \n",
      " 9   word_cleaning      10570 non-null  int64 \n",
      " 10  NOUN               10570 non-null  object\n",
      " 11  NOUN_count         10570 non-null  int64 \n",
      " 12  PROPN              10570 non-null  object\n",
      " 13  PROPN_count        10570 non-null  int64 \n",
      " 14  VERB               10570 non-null  object\n",
      " 15  VERB_count         10570 non-null  int64 \n",
      " 16  ADJ                10570 non-null  object\n",
      " 17  ADJ_count          10570 non-null  int64 \n",
      " 18  ADV                10570 non-null  object\n",
      " 19  ADV_count          10570 non-null  int64 \n",
      " 20  PRON               10570 non-null  object\n",
      " 21  PRON_count         10570 non-null  int64 \n",
      " 22  SCONJ              10570 non-null  object\n",
      " 23  SCONJ_count        10570 non-null  int64 \n",
      " 24  INTJ               10570 non-null  object\n",
      " 25  INTJ_count         10570 non-null  int64 \n",
      "dtypes: int64(12), object(14)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"serialized/data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>POS_spacy</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_cleaning</th>\n",
       "      <th>...</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADJ_count</th>\n",
       "      <th>ADV</th>\n",
       "      <th>ADV_count</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRON_count</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SCONJ_count</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>INTJ_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1</td>\n",
       "      <td>I hate to see such beautiful white females become victims of these sick  violent merciless animals .</td>\n",
       "      <td>hate to see such beautiful white females become victims of these sick violent merciless animals</td>\n",
       "      <td>[(hate, VERB), (to, PART), (see, VERB), (such, ADJ), (beautiful, ADJ), (white, ADJ), (females, NOUN), (become, VERB), (victims, NOUN), (of, ADP), (these, DET), (sick, ADJ), (violent, ADJ), (merciless, NOUN), (animals, NOUN)]</td>\n",
       "      <td>hate to see such beautiful white female become victim of these sick violent merciless animal</td>\n",
       "      <td>[hate, to, see, such, beautiful, white, females, become, victims, of, these, sick, violent, merciless, animals]</td>\n",
       "      <td>en</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>such beautiful white sick violent</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  \\\n",
       "187      1   \n",
       "\n",
       "                                                                                                     text  \\\n",
       "187  I hate to see such beautiful white females become victims of these sick  violent merciless animals .   \n",
       "\n",
       "                                                                                          text_clean  \\\n",
       "187  hate to see such beautiful white females become victims of these sick violent merciless animals   \n",
       "\n",
       "                                                                                                                                                                                                                            POS_spacy  \\\n",
       "187  [(hate, VERB), (to, PART), (see, VERB), (such, ADJ), (beautiful, ADJ), (white, ADJ), (females, NOUN), (become, VERB), (victims, NOUN), (of, ADP), (these, DET), (sick, ADJ), (violent, ADJ), (merciless, NOUN), (animals, NOUN)]   \n",
       "\n",
       "                                                                                       lemmatized  \\\n",
       "187  hate to see such beautiful white female become victim of these sick violent merciless animal   \n",
       "\n",
       "                                                                                                              tokens  \\\n",
       "187  [hate, to, see, such, beautiful, white, females, become, victims, of, these, sick, violent, merciless, animals]   \n",
       "\n",
       "    language  word_count_before  word_count  word_cleaning  ...  \\\n",
       "187       en                 17          15              2  ...   \n",
       "\n",
       "                                   ADJ  ADJ_count ADV  ADV_count PRON  \\\n",
       "187  such beautiful white sick violent          5              0        \n",
       "\n",
       "     PRON_count SCONJ  SCONJ_count INTJ  INTJ_count  \n",
       "187           0                  0                0  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "data[data['text'].str.contains('I hate to see such beautiful white ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
